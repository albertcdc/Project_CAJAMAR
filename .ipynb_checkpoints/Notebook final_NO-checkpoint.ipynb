{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Resumen i resultados obtenidos.\n",
    "\n",
    "En este trabajo se han utilizado dos métodos y algoritmos para predecir el siguiente producto a contratar por un cliente de un banco a partir del dataset proporcionado, el primer modelo és el más simple y el segundo más complejo. Finalmente se ha utilizado el más complejo para generar el dataset de entrega.\n",
    "\n",
    "Primero se ha intentado un modelo simple, basado en los últimos dos producto contratados por cada usuario y en una clasificación previa de usuarios. El siguiente producto a contratar se ha calculado con la fórmula de probabilidades de Bayes con un porcentaje de aciertos del 27%.\n",
    "\n",
    "\n",
    "\n",
    "El segundo modelo que se ha desarrollado se ha basado en métodos de Machine Learning(ML). Se ha hecho un pretratado de los datos, y se han clasificado los usuarios en 2 grupos según su actividad. Posteriormente se han extraído nuevas características de los datos. Finalmente, se han aplicado 2 modelos de ML se sklearn: RandomForestClassifier y GradientBoostingClassifier. Previamente se han optimizado los parametros de estos modelos mediante GridSearchCV.\n",
    "El modelo que ha dado mejor resultado ha sido un RandomForestClassifier, (el metodo GradientBoostingClassifier, da mejor resultado pero es mucho caro computacionalmente) con los parametros:\n",
    "{'n_estimators': 90, 'criterion': 'gini'} i 60000 muestras para el 20% de clientes activos.\n",
    "{'n_estimators': 40, 'criterion': 'gini'} i 100000 muestras para el 20% de clientes activos.\n",
    "\n",
    "\n",
    "Para calcular la bondad del modelo, se ha reservado un 20% de los datos provenientes del archivo train2.txt, para los 2 grupos de clientes creados.\n",
    "\n",
    "Se han calculado los errores de 2 formas distintas, siempre sobre un dataset de 'test', totalmente alieno al proceso de entrenamiento:\n",
    "- 'accuracy' sobre todos los productos:\n",
    "\n",
    "    20% más activo: 43,5%\n",
    "    \n",
    "    80% menos activo: 26,3%\n",
    "    \n",
    "    \n",
    "- 'accuracy' sin tener en cuenta el 10% de productos más comprados, para poder ver si el error se distribuye de manera uniforme para todos los productos:\n",
    "\n",
    "    20% más activo: 30,2%\n",
    "    \n",
    "    80% menos activo: 5,8%\n",
    "    \n",
    "    \n",
    "ESTOS RESULTADOS PUEDEN SER NOTABLEMENTE MEJORADOS SI SE INCORPORAN MÁS MUESTRAS I SE AUGMENTA LA COMPLEJIDAD DEL MODELO, AUNQUE EL TIEMPO DE COMPUTACIÓN VA A AUGMENTAR SIGNIFICATIVAMENTE.\n",
    "\n",
    "De este modo, so obtiene un modelo especializado en predecir qual va a ser el siguiente producto que van a comprar aquellos clientes que son más propensos a adquirir productos financieros, y que con notable seguridad, van a seguir adquiriéndolos. Tiene sentido focalizar el trabajo en estos clientes, ya que son los que generan mas negocio para la entidad bancaria.\n",
    "\n",
    "Por otro lado, el 80% de clientes pasivos son muy difíciles de predecir, puesto que hay poca información de ellos, e incluso en muchas ocasiones solo han comprado un solo producto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis exploratorio de los datos y comprensión de negocio:\n",
    "\n",
    "Después de explorar los datos proporcionados por la entidad, se observa que hay unos pocos productos que són muy comunes, mientras que otros son comprados en muy pocas ocasiones. Por otro lado, se ve que hay unos clientes que són muy activos, algunos han adquirido más de 20 productos, mientras que una gran mayoría de los clientes no compran más de 5 productos durante toda su relación con el banco.\n",
    "\n",
    "Debido a estos perfiles de clientes tan diferenciados, los bancos suelen clasificar a los clientes y los distinguen entre clientes activos y pasivos. Estas dos categorías responden a comportamientos y patrones de conducta distintos. Unos son consumidores que no desean contratar productos, que prefieren ahorrar y huyen de ofertas que no pueden entender del todo. Por otro lado hay clientes com menos aversión por el riesgo que no tienen miedo en hacer inversiones contratando diversos productos financieros.\n",
    "\n",
    "Conviene resaltar, que para evitar discriminaciones, el criterio de un banco para segmentar a sus clientes no puede basarse en razones de género, por lo que la variable que indica el género del cliente debe ser descartada.\n",
    "\n",
    "Se asume que el negocio de una entidad bancaria depende del número de productos contratados por los clientes. Acorde con el PRINCIPIO DE PARETO, también conocido como la regla del 80-20, por la que una población se puede separar en dos grupos de proporciones 80-20 tales que el grupo minoritario, formado por un 20% de población, genera el 80 % del beneficio y que el grupo mayoritario, formado por un 80% de población, el 20% de negocio restante. \n",
    "Se asume que el 20% de usuarios que generan más negocio son aquellos que compran más productos, y que por lo tanto es probable que sigan comportándose así, por lo que se considera interesante segmentar a los clientes entre el 20% de usuarios más activos i el 80% de usuarios más pasivos. LA FRONTERA ENTRE AMBOS GRUPOS SE SITUA EN LOS 7 PRODUCTOS ADQUIRIDOS.\n",
    "\n",
    "Por otro lado, también podemos hacer otra subclasificación dentro de los clientes de un banco. El nivel de ingresos de un usuario puede determinar con cierta probabilidad los productos que va a contratar. Así un cliente con ingresos altos y perfil activo va a estar abierto a muchos productos diferentes, mientras que un cliente pasivo con un nivel económico medio o bajo prácticamente no va a realizar actividad con la entidad y los productos a contratar van a ser los más comunes. También puede ser determinante la edad del cliente, puesto que a medida que va augmentando la edad, también lo hace la aversión al riesgo. Este tipo de segmentación, sólo se ha considerado para el modelo más simple, basado en Probabilidad Bayesiana\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulación de variables y su argumentación: eliminación, transformación y/o creación de nuevas variables:\n",
    "\n",
    "Cómo se comenta en el apartado de comprensión del negocio, se ELIMINA la variable que indica el género del cliente, ya que para evitar discriminaciones, el criterio de un banco para segmentar a sus clientes no puede basarse en razones de género.\n",
    "\n",
    "Se considera tener en cuenta el PRINCIPIO DE PARETO (REGLA 80-20) para la segmentación de los clientes en 2 grupos: el 20% de clientes más activos i el 80% de clientes más pasivos. Asumiendo que es este 20% de clientes que compran más productos, quien genera mayores beneficios para la entidad financiera, y que es el grupo de clientes que con mayor probabilidad va a comprar otro producto,se desarrolla un modelo focalizado en ellos.\n",
    "\n",
    "Para conservar la información de qué productos ha comprado cada cliente y en qué orden los ha comprado, se CREA/EXTRAE un nuevo vector de características del dataset. Este conjunto de características consiste en un vector de longitud 94, puesto que hay 94 productos distintos y cada elemento del vector representa un producto.\n",
    "EL valor de cada elemento del vector se obtiene de la siguiente forma:\n",
    "    - 0: si el producto representado por el elemento no ha sido comprado por el cliente\n",
    "    - 1/orden_inverso_de_compra si ha sido comprado.\n",
    "    \n",
    "    # EJEMPLO:\n",
    "    Suponiendo que hay 5 productos posibles: A, B, C, D, E, F.\n",
    "    \n",
    "    El Cliente1 ha comprado, por este orden, los productos: A(año 2010),C(año 2011),F(año 2012).\n",
    "    Por lo tanto el orden_inverso_de_compra sera: 3(prod A, más antiguo), 2 (prod B) i 1(prod C, más reciente).\n",
    "    \n",
    "    Esta NUEVA VARIABLE tiene un elemento para cada producto, por lo tanto tiene 6 campos (94 campos para el caso real de Cajamar).\n",
    "    \n",
    "    ENTONCES ESTA NUEVA VARIABLE SERÁ:\n",
    "                       A   B   C   D   E   F\n",
    "    nueva_variable = [1/3, 0, 1/2, 0,  0, 1/1]\n",
    "    \n",
    "    Ya que F es el último producto comprado, tendrá un valor mayor que C, el segundo producto más reciente y aún mayor que A, que es producto más antiguo.\n",
    "    \n",
    "    ****\n",
    "    ## DE ESTA FORMA, SE CONDENSA LA INFORMATION SOBRE QUÉ PRODUCTOS Y EN QUÉ ORDEN HA SIDO ADQUIRIDO PARA CADA USUARIO.\n",
    "    ****\n",
    "\n",
    "A esta nueva_variable creada, se le uniran la variables existentes que informan sobre la edad, antigüedad, ingresos y ocupación.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selección de modelo/s y ajuste de parámetros\n",
    "\n",
    "Se han utilizado 2 métodos:\n",
    "\n",
    "- Probabilidad Bayesiana: Utiliza sólo los dos últimos productos comprados para cada cliente. Es el modelo más sencillo, utilizado como punto de partida para corroborar que el siguiente método utilizado aporta valor a la predicción, o no lo aporta.\n",
    "\n",
    "- Clasificadores (Supervised ML, sklearn): Se han desarrollado modelos utilizando los métodos RandomForestClassifier y GradientBoostingClassifier.\n",
    "\n",
    "Para optimizar los parámetros de estos clasificadores, se ha utilizado la función GridSearchCV de sklearn, que permite comparar diversas configuraciones de parámetros y quedarse con aquella que da mejor resultado.\n",
    "\n",
    "Se observa que a más muestras, los modelos dan mejor resultado y requieren mas complejidad (augmentar el parametro \"n_estimators\", por ejemplo), lo que a su vez hace augmentar el tiempo de computación significativamente.\n",
    "\n",
    "RESULTADOS OBTENIDOS: un 43,5% de accuracy sobre todos los datos para los clientes más activos, un 30,2% si se excluyen aquellos que van a comprar un producto dentro de los 10% más comprados. El accuracy sobre los clientes pasivos es del 26,3%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elección de métrica elegida y justificación. Bondad del modelo\n",
    "\n",
    "Debido a que hay un grupo de pocos productos que son muy comunes, y luego está todo el resto de productos que son comprados con menos frecuencia, se ha considerado interesante medir la bondad del modelo aplicándolo sólo a aquellos clientes que no iban a comprar ninguno de los productos dentro del 10% de productos más comunes. Es decir, se ha calculado la bondad del modelo para aquellos casos más difíciles de predecir. \n",
    "\n",
    "Esto permite poder ver si el error se distribuye de manera uniforme para todos los productos, y no se concentra sólo en aquellos productos menos frecuentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretabilidad del modelo y viabilidad de puesta en producción\n",
    "\n",
    "Cada una de las variables utilizadas, tanto las propias del dataset inicial, como las creadas en este proyecto, tiene su significado y su lógica interpretación, como se ha explicado en el apartado de \"Manipulación de variables...\".\n",
    "\n",
    "Puesto que se han segmentado los clientes en 2 grupos (20% más activo y 80% más pasivo), se han obtenido 2 modelos distintos.\n",
    "\n",
    "Para la puesta en producción, simplemente hace falta clasificar cada cliente en uno de los dos segmentos:\n",
    " - 7 o más productos comprados: grupo del 20%\n",
    " - menos de 7 productos comprados: al grupo del 80%\n",
    " \n",
    "Una vez un cliente está clasificado, solo hace falta crear el vector de variables para ese cliente y ejecutar sobre este vector de variables el modelo correspondiente a su segmento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "############################################################################################################################\n",
    "# Método 1: Probabilidad bayesiana \n",
    "\n",
    "# Consideraciones:\n",
    "Previamente al cálculo se ha considerado que las siguientes variables no juegan un papel claro en este método: Socio_Demo_01 (edad), Socio_Demo_02 (antigüedad), Socio_Demo_04 (sexo) y Socio_Demo_05 (sector). Así que se ha descartado utilizarlas.\n",
    "\n",
    "\n",
    "De esta forma, se ha considerado oportuno clasificar los clientes el banco entre cuatro distintas categorías:\n",
    "\n",
    "- Categoría 1: clientes del 20% con ingresos altos. \n",
    "\n",
    "- Categoría 2: clientes del 20% con ingresos medios o bajos.\n",
    "\n",
    "- Categoría 3: clientes del 80% con ingresos altos.\n",
    "\n",
    "- Categoría 4: clientes del 80% con ingresos medios o bajos. \n",
    "\n",
    "# Método:\n",
    "\n",
    "En este modelo simple solamente nos fijamos en el último producto contratado para predecir el siguiente. Así, si un cliente ha comprado un producto B, tenemos que calcular la probabilidad de que después de B compre cualquier de los otros productos, y quedarnos con el que tenga una probabilidad más alta.\n",
    "\n",
    "Así, solo tenemos que contar el número de veces que sale el producto B con el producto A y el número de veces que sale el producto B.\n",
    "\n",
    "$$ P(A | B) = \\frac{P(B | A)P(A)}{P(B)} =  \\frac{\\frac{P(B∩A)}{P(A)}P(A)}{P(B)} = \\frac{P(B∩A)}{P(B)}$$\n",
    "\n",
    "\n",
    "Como hemos clasificado los usuarios en 4 categorías, primero tendremos que generar un vector con los dos últimos productos comprados por cada usuario en cada categoría. Una vez hecho esto, y para cada usuario de test, tendremos que clasificarlo en una de las 4 categorías dependiendo del número de productos que tiene y de los ingresos. Luego, cogeremos el último producto contratado y calcularemos las probabilidades del siguiente producto utilizando la fórmula de Bayes con el dataset de train de la categoría previamente seleccionada.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Código comentado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IMPORT TRAIN DATA\n",
    "data = pd.read_csv('train2.txt', header = 0, delimiter='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#How many different products do we have?\n",
    "different_produts = data.groupby('Cod_Prod').Cod_Prod.nunique()\n",
    "\n",
    "#First we will separate our data between 20% and 80% users:\n",
    "data_ID_byProd = data.groupby('ID_Customer').size().sort_values(ascending=False, )\n",
    "IDs_20 = data_ID_byProd.head(np.int(data_ID_byProd.size*0.2+1))\n",
    "IDs_80 = data_ID_byProd.tail(np.int(data_ID_byProd.size*0.8-1))\n",
    "ID20_idx = np.in1d(data.ID_Customer.values, IDs_20.index)\n",
    "data_IDs_20 = data.ix[ID20_idx]\n",
    "ID80_idx = np.in1d(data.ID_Customer.values, IDs_80.index)\n",
    "data_IDs_80 = data.ix[ID80_idx]\n",
    "\n",
    "#Let's create an array with all the different users that we have:\n",
    "data_users = data.groupby('ID_Customer').ID_Customer.nunique()\n",
    "\n",
    "#Now we will divide our data into 4 categories: \n",
    "# 1 - Users that buy a lot of producs (20%) with high income (Socio_Demo_03 > 3)\n",
    "# 2 - Users that buy a lot of products (20%) with midium or low income (Socio_Demo_03 <= 3)\n",
    "# 3 - Users that buy a few products (80%) with high income (Socio_Demo_03 > 3)\n",
    "# 4 - Users that buy a few products (80%) with medium or low income (Socio_Demo_03 <= 3)\n",
    "\n",
    "#The new data will be:\n",
    "\n",
    "# Category 1:\n",
    "users = data_users.sample(10000)\n",
    "data_20_high_income = data_IDs_20[(data_IDs_20.Socio_Demo_03 > 3)]\n",
    "data_20_high_income = data_20_high_income[data_20_high_income.ID_Customer.isin(users.index[:])]\n",
    "unique_users_20_high_income = data_20_high_income.groupby('ID_Customer').ID_Customer.nunique()\n",
    "\n",
    "# Category 2:\n",
    "users = data_users.sample(10000)\n",
    "data_20_low_income = data_IDs_20[(data_IDs_20.Socio_Demo_03 <= 3)]\n",
    "data_20_low_income = data_20_low_income[data_20_low_income.ID_Customer.isin(users.index[:])]\n",
    "unique_users_20_low_income = data_20_low_income.groupby('ID_Customer').ID_Customer.nunique()\n",
    "\n",
    "#Cateogry 3:\n",
    "users = data_users.sample(10000)\n",
    "data_80_high_income = data_IDs_80[(data_IDs_80.Socio_Demo_03 > 3)]\n",
    "data_80_high_income = data_80_high_income[data_80_high_income.ID_Customer.isin(users.index[:])]\n",
    "unique_users_80_high_income = data_80_high_income.groupby('ID_Customer').ID_Customer.nunique()\n",
    "\n",
    "# Category 4:\n",
    "users = data_users.sample(10000)\n",
    "data_80_low_income = data_IDs_80[(data_IDs_80.Socio_Demo_03 <= 3)]\n",
    "data_80_low_income = data_80_low_income[data_80_low_income.ID_Customer.isin(users.index[:])]\n",
    "unique_users_80_low_income = data_80_low_income.groupby('ID_Customer').ID_Customer.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#To check how well our model work we will select other random users to test:\n",
    "\n",
    "users = data_users.sample(1000)\n",
    "data_test = data[data.ID_Customer.isin(users.index[:])]\n",
    "unique_users_test = data_test.groupby('ID_Customer').ID_Customer.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def last_two_products(dataFrame,usr):   \n",
    "    \"\"\"\n",
    "    This function returns the last two products purchased by one user.\n",
    "    \"\"\"\n",
    "    \n",
    "    items = dataFrame[dataFrame.ID_Customer == usr].Cod_Fecha.size\n",
    "    \n",
    "    times = []\n",
    "    index_max = 0\n",
    "    index_product = np.zeros(items)\n",
    "    index_second_max = 0\n",
    "    \n",
    "    for i in range(items):\n",
    "        index_product[i] = dataFrame[dataFrame.ID_Customer == usr].index[i]\n",
    "        \n",
    "        data = dataFrame[dataFrame.ID_Customer == usr].Cod_Fecha[index_product[i]]\n",
    "        new_year, month = data.split('-')\n",
    "        new_time = float(new_year) + (float(month)/12)\n",
    "        times.append(float(new_time))\n",
    "    \n",
    "    #Index of last item purchased:\n",
    "    index_max = times.index(max(times))\n",
    "    times[index_max] = 0\n",
    "    #Index of second last item purchased:\n",
    "    index_second_max = times.index(max(times))\n",
    "    times[index_second_max] = 0\n",
    "    \n",
    "    last_product = dataFrame[dataFrame.ID_Customer == usr].Cod_Prod[index_product[index_max]]\n",
    "    second_last_product = dataFrame[dataFrame.ID_Customer == usr].Cod_Prod[index_product[index_second_max]]\n",
    "\n",
    "    return second_last_product, last_product\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#We will now generate two vectors with the last two products purchased by the forth categories of users that we made before:\n",
    "\n",
    "# Category 1:\n",
    "second_last_products_20_high_income = []\n",
    "last_products_20_high_income = []\n",
    "\n",
    "for i in range(unique_users_20_high_income.size):\n",
    "\n",
    "    second_last_product, last_product = last_two_products(data_20_high_income, unique_users_20_high_income.index[i])\n",
    "\n",
    "    if second_last_product != last_product:\n",
    "        second_last_products_20_high_income.append(second_last_product)\n",
    "        last_products_20_high_income.append(last_product)\n",
    "\n",
    "        \n",
    "# Category 2:\n",
    "second_last_products_20_low_income = []\n",
    "last_products_20_low_income = []\n",
    "\n",
    "for i in range(unique_users_20_low_income.size):\n",
    "\n",
    "    second_last_product, last_product = last_two_products(data_20_low_income, unique_users_20_low_income.index[i])\n",
    "\n",
    "    if second_last_product != last_product:\n",
    "        second_last_products_20_low_income.append(second_last_product)\n",
    "        last_products_20_low_income.append(last_product)\n",
    "\n",
    "        \n",
    "# Category 3:\n",
    "second_last_products_80_high_income = []\n",
    "last_products_80_high_income = []\n",
    "\n",
    "for i in range(unique_users_80_high_income.size):\n",
    "\n",
    "    second_last_product, last_product = last_two_products(data_80_high_income, unique_users_80_high_income.index[i])\n",
    "\n",
    "    if second_last_product != last_product:\n",
    "        second_last_products_80_high_income.append(second_last_product)\n",
    "        last_products_80_high_income.append(last_product)\n",
    "\n",
    "        \n",
    "# Category 4:\n",
    "second_last_products_80_low_income = []\n",
    "last_products_80_low_income = []\n",
    "\n",
    "for i in range(unique_users_80_low_income.size):\n",
    "\n",
    "    second_last_product, last_product = last_two_products(data_80_low_income, unique_users_80_low_income.index[i])\n",
    "\n",
    "    if second_last_product != last_product:\n",
    "        second_last_products_80_low_income.append(second_last_product)\n",
    "        last_products_80_low_income.append(last_product)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We will now create a function that returns the most likly product that a user will buy afeter buying one product. \n",
    "\n",
    "def next_product(number,different_produts,second_last_products,last_products):\n",
    "    \"\"\"\n",
    "    This function returns the product most likely that a user will buy based on the last product purchased ('number') and\n",
    "    the vectors 'second_last_products' and 'last_products'\n",
    "    \"\"\"\n",
    "    \n",
    "    count_down = 0\n",
    "\n",
    "    for i in range(len(last_products)):\n",
    "        if (last_products[i] == number) or (second_last_products[i] == number):\n",
    "            count_down += 1        \n",
    "            \n",
    "    likelihood = np.zeros(different_produts.size)\n",
    "\n",
    "    for j in range(different_produts.size):\n",
    "\n",
    "        count_up = 0\n",
    "        number_last = different_produts.index[j]\n",
    "        number_second = number\n",
    "\n",
    "        for i in range(len(last_products)):\n",
    "            if (last_products[i] == number_last) and (second_last_products[i] == number_second):\n",
    "                count_up += 1 \n",
    "        try:\n",
    "            likelihood[j] = 100*float(count_up)/float(count_down)\n",
    "        except:\n",
    "            likelihood[j] = 0\n",
    "\n",
    "    index = np.argmax(likelihood)\n",
    "    \n",
    "    return different_produts.index[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now let's test how our model works with the test data created before. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#First we will extract the last product and second last product purchased by our test users. For the prediccion we will use\n",
    "# the second last product, and to check how well our model works we will use the last product purchased.\n",
    "\n",
    "product_previous = []\n",
    "product_match = []\n",
    "\n",
    "for i in range(int(unique_users_test.size)):\n",
    "    \n",
    "    second_last_product, last_product = last_two_products(data_test, unique_users_test.index[i])\n",
    "\n",
    "    product_previous.append(second_last_product)\n",
    "    product_match.append(last_product)\n",
    "    \n",
    "#And now we make the prediccion:\n",
    "\n",
    "values = np.zeros(len(product_previous))\n",
    "\n",
    "for i in range(int(unique_users_test.size)):\n",
    "    \n",
    "    # Number of products purchased by the user:\n",
    "    total_number_products = data_test[data_test.ID_Customer == unique_users_test.index[i]].Cod_Prod.size - 1\n",
    "    \n",
    "    # Income of the user:\n",
    "    income = data_test[data_test.ID_Customer == unique_users_test.index[i]].Socio_Demo_03.mean()\n",
    "    \n",
    "    if total_number_products >= 7 :\n",
    "        if income >= 3: \n",
    "            # Category 1:\n",
    "            values[i] =next_product(product_previous[i],different_produts,second_last_products_20_high_income,last_products_20_high_income)\n",
    "        else:\n",
    "            #Category 2:\n",
    "            values[i] =next_product(product_previous[i],different_produts,second_last_products_20_low_income,last_products_20_low_income)\n",
    "    else:\n",
    "        if income >= 3:\n",
    "            # Category 3:\n",
    "            values[i] =next_product(product_previous[i],different_produts,second_last_products_80_high_income,last_products_80_high_income)\n",
    "        else:\n",
    "            # Category 4:\n",
    "            values[i] =next_product(product_previous[i],different_produts,second_last_products_80_low_income,last_products_80_low_income)\n",
    "            \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our model can predict the next product that a user will buy with a score of  29.3 %\n"
     ]
    }
   ],
   "source": [
    "correct_answer = 0\n",
    "\n",
    "for i in range(len(product_match)):\n",
    "       \n",
    "    if product_match[i] == values[i]:\n",
    "        correct_answer += 1\n",
    "\n",
    "score = 100*float(correct_answer) / float(len(product_match))\n",
    "print 'Our model can predict the next product that a user will buy with a score of ', score, '%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Conclusiones\n",
    "\n",
    "Con un método sencillo, basado en probabilidades bayesianas y haciendo una clasificación previa de usuarios, se ha conseguido unos resultados con aciertos promedio del 27%. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "########################################################################################################################\n",
    "# Método 2: Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
